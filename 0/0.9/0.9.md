# 0.9. Trabajo Individual - Patrones Cloud (Informes y Videos)

## Manuel Malpartida - Retry

# El Patrón Retry En Sistemas de E-Commerce

## Introducción
El patrón Retry es un mecanismo de tolerancia a fallos diseñado para manejar errores transitorios en sistemas distribuidos. En el contexto de e-commerce, donde la disponibilidad y experiencia del usuario son críticas, este patrón permite recuperarse automáticamente de fallas temporales en servicios externos como pasarelas de pago, APIs de inventario o sistemas de recomendación.

## ¿Qué es el Patrón Retry?
El patrón Retry actúa como un sistema de recuperación automática que:

- Detecta fallas temporales (timeouts, errores HTTP 5xx)
- Reintenta la operación fallida siguiendo una política configurable
- Implementa tiempos de espera entre reintentos (backoff)
- Finaliza cuando tiene éxito o alcanza el límite de intentos

**Ejemplo en e-commerce**:

- Cliente → [Intento de pago → Falla temporal → Espera 1s → Reintento → Éxito]

## Problema que Resuelve en E-Commerce
**Desafíos comunes**:
- Pagos fallidos: 15-20% de transacciones fallan inicialmente por inestabilidad en APIs de pago
- Disponibilidad de inventario: Contenciones en bases de datos durante ofertas flash
- Recomendaciones: Latencia variable en servicios de ML
- Notificaciones: Fallos en envío de emails/notificaciones push

**Consecuencias sin Retry**:
- Pérdida de ventas por fallas evitables
- Mala experiencia de usuario (errores visibles)
- Inconsistencias en datos críticos

## Arquitectura del Patrón
**Componentes clave**:
1. **Detector de fallas transitorias**: Clasifica errores como recuperables
2. **Política de reintentos**: Define máximo de intentos y tiempos de espera
3. **Estrategia de backoff**: Calcula intervalos entre reintentos (ej: exponencial)
4. **Mecanismo de fallback**: Acción alternativa cuando se agotan los reintentos

**Flujo típico**:
1. Operación falla por error transitorio
2. Sistema espera un intervalo calculado
3. Reintenta la operación
4. Repite hasta éxito o límite de intentos

## Implementación en E-Commerce
**Tecnologías recomendadas**:
- Node.js: `async-retry`, `promise-retry`
- Java: Spring Retry, Resilience4j
- .NET: Polly
- Python: Tenacity

### Ejemplo práctico (Servicio de Pagos)
```javascript
const retry = require('async-retry');

// Simulador de servicio de pagos con fallas controladas
let attemptCount = 0;
const mockPaymentGateway = {
  charge: async (paymentData) => {
    attemptCount++;
    console.log(`🔵 Intento #${attemptCount} - Procesando pago $${paymentData.amount}`);
    
    // Simulamos fallas temporales en los primeros 2 intentos
    if (attemptCount < 3) {
      throw new Error('Error temporal: Servicio de pagos no disponible');
    }
    
    return { success: true, transactionId: `txn_${Date.now()}` };
  }
};

// Implementación con patrón Retry
async function processPayment(paymentData) {
  try {
    return await retry(
      async (bail) => {
        try {
          return await mockPaymentGateway.charge(paymentData);
        } catch (error) {
          if (error.message.includes('temporal')) {
            console.log(`🟡 ${error.message} - Reintentando...`);
            throw error;
          }
          bail(error);
          return;
        }
      },
      {
        retries: 3,
        minTimeout: 1000,
        factor: 2,
        onRetry: (error) => {
          console.log(`⏳ Esperando ${error.attemptNumber * 1}s...`);
        }
      }
    );
  } catch (error) {
    console.error(`🔴 Error final: ${error.message}`);
    return { success: false };
  }
}

// Ejecución de prueba
(async () => {
  console.log('=== DEMO PATRÓN RETRY EN E-COMMERCE ===');
  const result = await processPayment({ amount: 99.99 });
  console.log('Resultado final:', result);
})();
 
```

## Casos de Uso en E-Commerce

### Procesamiento de pagos:
- Reintentos cuando fallan conexiones con Stripe/PayPal.
- Backoff exponencial para evitar saturar el servicio.

### Reserva de inventario:
- Reintentos ante errores de concurrencia.
- Jitter para distribuir la carga.

### Sistema de recomendaciones:
- Reintentos con degradación elegante (muestra resultados en caché primero).

### Notificaciones:
- Reintentos para enviar emails/notificaciones push.
- Encolamiento como fallback.

## Ventajas y Consideraciones

### Beneficios:
✓ Mayor tasa de éxito en transacciones.  
✓ Mejor experiencia de usuario (menos errores visibles).  
✓ Resiliencia automática ante fallas temporales.  

### Riesgos:
✗ Puede enmascarar problemas subyacentes si no se monitorea.  
✗ Posible saturación si no se configura adecuadamente.  
✗ No aplicable a operaciones no idempotentes.  

## Mejores Prácticas
- Configurar límites razonables (3-5 reintentos).
- Usar backoff exponencial + jitter para evitar sincronización.
- Implementar circuit breakers para fallas prolongadas.
- Monitorear métricas de reintentos (indicador de problemas).
- Evitar en operaciones no idempotentes (ej: POST que crean recursos).

## Conclusión
En sistemas de e-commerce, el patrón Retry es esencial para manejar la inevitable inestabilidad de servicios distribuidos. Cuando se implementa correctamente, puede reducir fallas visibles al usuario en más del 50%, mejorando significativamente la experiencia de compra y las métricas de conversión.

# Video:

link: https://youtu.be/NrjG9d0cYWw 

## Integrante 2




## 📌 1.  Elección de Tema:

# 🧠 Implementación del Patrón Cloud – Convoy Secuencial

## 📌 2.  Desarrollo del Patrón:


## Problema que resuelve el patrón Convoy Secuencial

En sistemas distribuidos, especialmente aquellos que procesan mensajes en paralelo, surge un problema cuando:

- Se deben procesar mensajes **en orden por grupo** (ej. por cliente o por cuenta).
- El procesamiento de un grupo **bloquea a otros** si se hace secuencialmente.

### ❗ Ejemplos de problemas:

- Inconsistencias por procesar transacciones fuera de orden.
- Cuellos de botella si un proceso lento detiene todo el flujo.
- Ineficiencia al aplicar bloqueo global en lugar de por grupo.

---

## ✅ Solución que propone el patrón

El patrón **Sequential Convoy** permite procesar mensajes relacionados **en orden dentro de su grupo**, pero **sin bloquear otros grupos**. Se basa en:

- Agrupación por claves (por ejemplo, `user_id`, `tenant_id`, `account_id`).
- Particionado de colas o tópicos por clave.
- Procesamiento concurrente entre grupos, pero ordenado dentro de cada uno.

### 🔧 Tecnologías recomendadas:

- Apache Kafka (particiones por clave).
- Azure Service Bus (session-enabled queues).
- AWS Kinesis (shard key).
- RabbitMQ (routing keys).

---

## 🏭  Casos de aplicación reales :



| Industria   | Caso de uso                              | Aplicación del patrón Convoy Secuencial |
|------------|-------------------------------------------|------------------------------------------|
| Bancaria   | Transacciones por cuenta                  | Mantiene el orden de depósitos y retiros |
| E-commerce | Pedidos por cliente                       | Asegura consistencia en stock y despacho |
| Logística  | Seguimiento de paquetes                   | Procesa eventos en orden por tracking ID |
| SaaS       | Acciones por tenant (cliente empresarial) | Aísla el procesamiento por cliente       |

---


## 📌 3.  Desarrollo del Patrón:


## 💻 Proyecto de ejemplo: Procesamiento de Pedidos por Cliente

Este proyecto simula el procesamiento de pedidos en un sistema Kafka con múltiples particiones. Cada pedido se asocia a un usuario, y se garantiza el orden por usuario.

### 🗂️ Estructura del proyecto


sequential-convoy/
├── docker-compose.yml
├── producer.js
└── consumer.js




---

### 🐳 docker-compose.yml

```yaml
version: '2'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1


📦 producer.js

const { Kafka } = require("kafkajs");

const kafka = new Kafka({ clientId: "producer", brokers: ["localhost:9092"] });
const producer = kafka.producer();

const sendOrders = async () => {
  await producer.connect();

  const users = ["user1", "user2", "user3"];

  for (let i = 0; i < 10; i++) {
    const user = users[i % users.length];
    const order = {
      orderId: `order-${i}`,
      user,
      timestamp: new Date().toISOString(),
    };

    await producer.send({
      topic: "orders",
      messages: [
        {
          key: user,
          value: JSON.stringify(order),
        },
      ],
    });

    console.log(`📦 Enviado pedido: ${JSON.stringify(order)}`);
  }

  await producer.disconnect();
};

sendOrders();



✅ consumer.js

const { Kafka } = require("kafkajs");

const kafka = new Kafka({ clientId: "consumer", brokers: ["localhost:9092"] });

const consumer = kafka.consumer({ groupId: "order-group" });

const run = async () => {
  await consumer.connect();
  await consumer.subscribe({ topic: "orders", fromBeginning: true });

  await consumer.run({
    eachMessage: async ({ topic, partition, message }) => {
      const pedido = JSON.parse(message.value.toString());

      console.log(
        `✅ Procesando pedido ${pedido.orderId} de ${pedido.user} en partición ${partition}`
      );
    },
  });
};

run();

## PASOS ADICIONALES:

## 🧪 ¿Cómo probarlo?

### 🚀 Levanta Kafka y Zookeeper:

```bash
docker-compose up -d

📦 Instala las dependencias:
npm init -y
npm install kafkajs
🧵 (Opcional) Crea el tópico si es necesario:
kafka-topics.sh --create --topic orders --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
🛠️ Ejecuta el consumidor:
node consumer.js
📨 En otra terminal, ejecuta el productor:
node producer.js


🎯 Resultado Esperado
Los pedidos de cada usuario serán procesados en orden (convoy secuencial), pero sin bloquear el procesamiento de otros usuarios gracias al uso de claves (por usuario) y particiones en Kafka.



## 📌 4.Entrega:



## 🧪 Repositorio

🔗 Repositorio del código:  
👉 [Proyecto Convoy Secuencial en GitHub](https://github.com/HaroldUlima/ProyectoFinal/blob/main/Proyecto_convoy_secuencial)

---

## 🎥 Video de Demostración

📽️ Link al video en YouTube:  
👉 [Demo Patrón Convoy Secuencial - YouTube](https://www.youtube.com/watch?v=sTbShpPbV3E)

---

## 📚 Fuentes y Lectura Recomendada

- 🔗 [KafkaJS - Documentación Oficial](https://kafka.js.org/)
- 🔗 [Azure: Patrón Convoy Secuencial](https://learn.microsoft.com/en-us/azure/architecture/patterns/sequential-convoy)

---

## 📋 Detalles Técnicos

1. Se crea un tópico Kafka llamado `orders` con **3 particiones**.
2. Cada mensaje contiene una **clave de usuario** para asegurar que todos sus mensajes vayan a la misma partición.
3. El consumidor utiliza **KafkaJS** para escuchar y procesar los mensajes en orden.
4. Se simulan múltiples usuarios enviando órdenes, y se observa cómo Kafka mantiene el orden por grupo sin afectar otros grupos.

---

## 🧠 Conclusión

El patrón convoy secuencial permite mantener la lógica de orden sin comprometer la concurrencia del sistema. Este tipo de diseño es clave para arquitecturas de microservicios donde el procesamiento ordenado por contexto (usuario, sesión, transacción) es fundamental.


## Integrante 3
Diego Saravia

Ejecución del Proceso: Implementar Cache-aside con Redis y Node.js

Paso 1: Requisitos previos
1. Instalar Node.js
2. Instalar Redis
sudo apt update
sudo apt install redis-server

Paso 2: Crear el proyecto

Paso 3: Crear el archivo del servidor
Crea el archivo server.js:
touch server.js

const express = require('express');
const redis = require('redis');

const app = express();
const port = 3000;

// Crear cliente de Redis
const client = redis.createClient();

client.connect().catch(console.error);

// Simular base de datos
const fakeDB = {
  1: { id: 1, name: "Laptop", price: 1200 },
  2: { id: 2, name: "Mouse", price: 25 },
  3: { id: 3, name: "Keyboard", price: 45 }
};

// Endpoint con estrategia cache-aside
app.get('/product/:id', async (req, res) => {
  const id = req.params.id;

  try {
    // 1. Buscar en caché
    const cached = await client.get(`product:${id}`);
    if (cached) {
      return res.json({ source: "cache", data: JSON.parse(cached) });
    }

    // 2. Buscar en "base de datos"
    const product = fakeDB[id];
    if (!product) return res.status(404).json({ error: "Producto no encontrado" });

    // 3. Guardar en caché por 60 segundos
    await client.setEx(`product:${id}`, 60, JSON.stringify(product));

    // 4. Responder con datos de base de datos
    res.json({ source: "database", data: product });

  } catch (err) {
    console.error("Error:", err);
    res.status(500).json({ error: "Error interno" });
  }
});

app.listen(port, () => {
  console.log(`Servidor en http://localhost:${port}`);
});

Paso 4: Ejecutar el servidor
node server.js
Servidor en http://localhost:3000

Paso 5: Probar el endpoint
Abrir navegador o usa Postman/cURL:
Después de 60 segundos:
Redis elimina el valor (por TTL), y se vuelve a consultar la “base de datos”.


## Integrante 4
## Integrante 5
## Integrante 6